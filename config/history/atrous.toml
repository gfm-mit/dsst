[sgd]
  # competitive, oddly enough
  scheduler='none'
  optimizer='sgd'
  weight_decay=0
  momentum=0.5
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=800
  min_epochs=3
  learning_rate=2e-1

[onecyclesgd]
  # better than sgd, but annoying
  scheduler='onecycle'
  optimizer='sgd'
  weight_decay=0
  momentum=0.5
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=800
  min_epochs=3
  learning_rate=2e-1

[sfsgd]
  # gives out around step 300
  scheduler='none'
  optimizer='sfsgd'
  weight_decay=0
  momentum=0.5
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=800
  min_epochs=3
  learning_rate=2e-1

[samsgd]
  # scary good.  crosses .85 on validation after 800 steps
  scheduler='none'
  optimizer='samsgd'
  weight_decay=0
  momentum=0.5
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=800
  min_epochs=3
  learning_rate=2e-1

[adam]
  # not helpful for convex
  scheduler='none'
  optimizer='adam'
  weight_decay=0
  momentum=0.9
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=800
  min_epochs=3
  learning_rate=1e-2

[onecycleadam]
  scheduler='onecycle'
  optimizer='adam'
  weight_decay=0
  momentum=0.9
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=800
  min_epochs=3
  learning_rate=1e-2

[sfadam]
  # gives out around step 300
  scheduler='none'
  optimizer='sfadam'
  weight_decay=0
  momentum=0.5
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=800
  min_epochs=3
  learning_rate=1e-2

[samadam]
  # useless on convex problem, apparently
  scheduler='none'
  optimizer='samadam'
  weight_decay=0
  momentum=0.5
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=800
  min_epochs=3
  learning_rate=1e-2

[lion]
  # terrible performance
  scheduler='none'
  optimizer='lion'
  weight_decay=0
  momentum=0.5
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=800
  min_epochs=3
  learning_rate=1e-2

[prodigy]
  # gives out around step 300, like "sf" versions
  scheduler='none'
  optimizer='prodigy'
  weight_decay=0
  momentum=0.5
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=800
  min_epochs=3
  learning_rate=1