[sgd]
  # noticeably worse than samsgd
  scheduler='none'
  optimizer='sgd'
  weight_decay=0
  momentum=0.5
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=1200
  min_epochs=3
  learning_rate=2e-1

[onecyclesgd]
  # about halfway from plain sgd to sam
  scheduler='onecycle'
  optimizer='sgd'
  weight_decay=0
  momentum=0.5
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=1200
  min_epochs=3
  learning_rate=2e-1

[sfsgd]
  # gives out around step 300
  scheduler='none'
  optimizer='sfsgd'
  weight_decay=0
  momentum=0.5
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=800
  min_epochs=3
  learning_rate=2e-1

[samsgd]
  # scary good.  crosses .85 on validation after 1200 steps
  scheduler='none'
  optimizer='samsgd'
  weight_decay=0
  momentum=0.5
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=1200
  min_epochs=3
  learning_rate=2e-1

[adam]
  # underperforms onecycle and sam versions
  scheduler='none'
  optimizer='adam'
  weight_decay=0
  momentum=0.9
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=1200
  min_epochs=3
  learning_rate=1e-2

[onecycleadam]
  # way underperforms samadam, slightly outperforms adam
  scheduler='onecycle'
  optimizer='adam'
  weight_decay=0
  momentum=0.9
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=400
  min_epochs=3
  learning_rate=1e-2

[sfadam]
  # gives out around step 300
  scheduler='none'
  optimizer='sfadam'
  weight_decay=0
  momentum=0.5
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=800
  min_epochs=3
  learning_rate=1e-2

[samadam]
  # noticeably better than samsgd
  scheduler='none'
  optimizer='samadam'
  weight_decay=0
  momentum=0.5
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=1200
  min_epochs=3
  learning_rate=1e-2

[lion]
  # terrible performance
  scheduler='none'
  optimizer='lion'
  weight_decay=0
  momentum=0.5
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=800
  min_epochs=3
  learning_rate=1e-2

[prodigy]
  # gives out around step 300, like "sf" versions
  scheduler='none'
  optimizer='prodigy'
  weight_decay=0
  momentum=0.5
  conditioning_smoother=0.999
  warmup_steps=5
  max_epochs=800
  min_epochs=3
  learning_rate=1